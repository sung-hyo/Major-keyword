{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled8.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "lia1xWguKdbV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Bootstrap(붓스트랩)\n",
        "---\n",
        "    - boot + strap 의 합성어로 긴 부츠의 뒷부분에 달린 고리를 뜻한다. \n",
        "    - 브래들리 에프론(Bradley Efron)이 1979년에 제안한 방법으로, 표본에 대해 더 자세히 알기 위해 사용한다. 2000년대 이후 컴퓨터의 연산능력이 제고됨에 따라 베이즈 통계와 함께 주목을 받고 있다.\n",
        "    - 주어진 표본(샘플)에 대해서 그 샘플에서 또 다시 재표집(resampling)을 여러번 추출하여 표본의 평균이나 분산 등의 분포를 알 수 있다.\n",
        "    - 모집단 iid(Independent and identically distributed) 가정을 만족해야 하며, 재표집의 수가 적을 경우 이상값의 영향을 받을 수 있다. "
      ]
    },
    {
      "metadata": {
        "id": "gDYGIauFJO6e",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Bagging(배깅, bootstrap aggregating)\n",
        "---\n",
        "    - 통계적 분류와 회귀 분석에서 사용되는 기계 학습 알고리즘의 안정성과 정확도를 향상시키기 위해 고안된 일종의 앙상블 학습법의 메타 알고리즘이다. 또한 배깅은 분산을 줄이고 과적합(overfitting)을 피하도록 해준다. 결정 트리 학습법이나 랜덤 포레스트에만 적용되는 것이 일반적이기는 하나, 그 외의 다른 방법들과 함께 사용할 수 있다\n",
        "    \n",
        "    - n크기의 훈련 집합(training set)이 주어졌을 때, 배깅은 m개의 복원표본추출(sampling with replacement)방법과 균등 확률분포를 이용해 각각 n'크기를 갖는 새로운 훈련 집한을 생성한다. \n",
        "    - m개의 모델은 m개의 bootstrap sample을 이용해 만들어지고 결과를 평균(회귀분석) 또는 투표(분류)를 통해 결합한다. \n",
        "    \n",
        "![bagging](https://swalloow.github.io/assets/images/boosting.png)\n",
        "<출처: http://swalloow.github.io/bagging-boosting>"
      ]
    },
    {
      "metadata": {
        "id": "9PMWJGBjLd8c",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Boosting(부스팅)\n",
        "---\n",
        "    - 모델이 잘 예측하지 못하는 부분을 개선하기 위한 모델이다. \n",
        "    - 전체 데이터에서 여러 샘플링 데이터를 추출하여 순차적으로 이전 학습 분류기의 결과를 토대로 다음 학습 데이터의 샘플 가중치를 조정하면서 학습을 진행\n",
        "    - 순차적인 모델에서 이전 모델들이 잘 예측하지 못하는 error 데이터에 가중치를 부여하여 다음 모델이 더 잘 예측하도록 한다. \n",
        "    - 이상값이 취약한 단점이 있다.\n",
        "\n",
        "![boosting](http://www.birc.co.kr/wp-content/uploads/2017/02/boosting.png)\n",
        "<출처: http://www.birc.co.kr/wp-content/uploads/2017/02/boosting.png> "
      ]
    },
    {
      "metadata": {
        "id": "ghtz11JtOWsL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 앙상블\n",
        "-----\n",
        "    - 동일한 학습 알고리즘을 사용하여 여러모델을 학습하는 개념이다. \n",
        "\n",
        "![boosting](https://quantdare.com/wp-content/uploads/2016/04/bb1-800x221.png)\n",
        "\n",
        "* 배깅과 부스팅의 샘플링\n",
        "\n",
        "![boosting](https://quantdare.com/wp-content/uploads/2016/04/bb2-800x307.png)\n",
        "\n",
        "* 가중치를 왜 주는가?\n",
        "\n",
        "![boosting](https://quantdare.com/wp-content/uploads/2016/04/bb3-800x307.png)\n",
        "\n",
        "* 분류 단계의 작업\n",
        "\n",
        "![boosting](https://quantdare.com/wp-content/uploads/2016/04/bb4-800x307.png)\n",
        "\n",
        "![boosting](https://quantdare.com/wp-content/uploads/2016/04/bb5-800x285.png)\n",
        "\n",
        "<출처 : https://quantdare.com/what-is-the-difference-between-bagging-and-boosting/>\n"
      ]
    },
    {
      "metadata": {
        "id": "oLFuqb9QNITL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Stacking\n",
        "----\n",
        "    - Meta modeling이라고 부르는 방법으로 “Two heads are better than one” 이라는 아이디어에서 출발하였다. \n",
        "    - 서로 다른 모델들을 조합해서 최고의 성능을 내는 모델을 생성한다. \n",
        "    - 서로의 장점을 취하고 약점을 보완할 수 있게 된다. \n",
        "    - 연산량이 매우 크다. \n",
        "    "
      ]
    },
    {
      "metadata": {
        "id": "g9W5kGibJOum",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}